{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for natural language generation\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Activation, Flatten, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from textgenrnn import textgenrnn\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'rnn_size': 50,\n",
    "    'rnn_layers': 4,\n",
    "    'rnn_bidirectional': True,\n",
    "    'max_length': 15,\n",
    "    'max_words': 10000,\n",
    "    'dim_embeddings': 100,\n",
    "    'word_level': False,\n",
    "}\n",
    "training_config = {\n",
    "    'line_delimited': True,\n",
    "    'num_epochs': 2,\n",
    "    'batch_size': 750,\n",
    "    'train_size': 0.8,\n",
    "    'dropout': 0.2,\n",
    "    'max_gen_length': 300,\n",
    "    'validation': True,\n",
    "    'is_csv': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 100)      46500       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (LSTM)                    (None, 40, 128)      117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (LSTM)                    (None, 40, 128)      131584      rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 356)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 356)          356         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 465)          166005      attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 461,693\n",
      "Trainable params: 461,693\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = 'kendrick_model'\n",
    "textgen = textgenrnn(name=model_name)\n",
    "textgen.model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,908 texts collected.\n",
      "Training new model w/ 4-layer, 50-cell Bidirectional LSTMs\n",
      "Training on 353,201 character sequences.\n",
      "Epoch 1/2\n",
      "470/470 [==============================] - ETA: 0s - loss: 2.2416####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "i want the way me when i want the see a beat a but a feel the mord me and the ward the beath my come and when you a want the street what i see the couse of my beat what you beat a beat the stare and i see my shit\n",
      "\n",
      "but the beat i want a but the way a bout the want the down the score\n",
      "\n",
      "that's when i want a but i sand the want i wann the come the strick in the back that some me when i can the made and the pare in the want a but i want a beat the way the can in the back the beat a but a but my beat i want the back the can my beat the beat and my but i want a soun a but my me\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "but i what that somes where the weaked to hough\n",
      "\n",
      "lookin' a sears the wondamon and my canduce\n",
      "\n",
      "i sand no when when you back the spick the reale\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "it's a leares im the wall in\n",
      "\n",
      "ware you'rem vuse thryseef you be\n",
      "\n",
      "fuckded to can with i wankin' no choddac like bettysing goo\n",
      "\n",
      "470/470 [==============================] - 295s 627ms/step - loss: 2.2416 - val_loss: 1.8441 - lr: 0.0040\n",
      "Epoch 2/2\n",
      "470/470 [==============================] - ETA: 0s - loss: 1.7756####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "i was the probably should and the game and the fuck the start the feeling and the probably for the fuck it the start and the fuck is the proce the fuck and the probably the street the street the shit it i was a but you don't love for the fuck the getter and the start and the prose and the street th\n",
      "\n",
      "the start the shit\n",
      "\n",
      "i got a don't got a but i was the street and the probably that you was to the street the fuck it i got a be the start the start the street in the street and the start the street the morter and the gold and the street and the start and the better should and the start in the morter the shit\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "say they got now\n",
      "\n",
      "and i shat my nigga\n",
      "\n",
      "i gotta should it the game of you, or shit home for my trouse\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "box though ig yeah, i wanna jesk want just duckal nexil\n",
      "\n",
      "mean short on i'm oven, like a specty fuck smort do lood\n",
      "\n",
      "came thus eonly\n",
      "\n",
      "470/470 [==============================] - 302s 643ms/step - loss: 1.7756 - val_loss: 1.7123 - lr: 0.0020\n"
     ]
    }
   ],
   "source": [
    "train_function = textgen.train_from_file\n",
    "\n",
    "train_function(\n",
    "    file_path='data/kendrick_lamar.txt',\n",
    "    new_model=True,\n",
    "    weights_path=\"model/kendrick_model.hdf5\",\n",
    "    vocab_path=\"model/kendrick_model_vocab.json\",\n",
    "    config_path=\"model/kendrick_model_config.json\",\n",
    "    num_epochs=training_config['num_epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    train_size=training_config['train_size'],\n",
    "    dropout=training_config['dropout'],\n",
    "    max_gen_length=training_config['max_gen_length'],\n",
    "    validation=training_config['validation'],\n",
    "    is_csv=training_config['is_csv'],\n",
    "    rnn_layers=model_config['rnn_layers'],\n",
    "    rnn_size=model_config['rnn_size'],\n",
    "    rnn_bidirectional=model_config['rnn_bidirectional'],\n",
    "    max_length=model_config['max_length'],\n",
    "    dim_embeddings=model_config['dim_embeddings'],\n",
    "    word_level=model_config['word_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/kendrick_model_config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c5d61134215b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m textgen = textgenrnn(weights_path='model/kendrick_model.hdf5',\n\u001b[1;32m      2\u001b[0m                        \u001b[0mvocab_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model/kendrick_model_vocab.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                        config_path='model/kendrick_model_config.json')\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtextgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weights_path, vocab_path, config_path, name, allow_growth)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             with open(config_path, 'r',\n\u001b[0;32m---> 61\u001b[0;31m                       encoding='utf8', errors='ignore') as json_file:\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/kendrick_model_config.json'"
     ]
    }
   ],
   "source": [
    "textgen = textgenrnn(weights_path='kendrick_model.hdf5',\n",
    "                       vocab_path='kendrick_model_vocab.json',\n",
    "                       config_path='kendrick_model_config.json')\n",
    "\n",
    "textgen.generate_samples(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
